{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Imports\n",
    "\n",
    "- numpy will be handy for mathematical functions.\n",
    "- matplotlib will be used for the visualisation of the maze. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as pn\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Maze\n",
    "\n",
    "- Using matplotplib we use arrays filled with zeros (open space) and ones (walls) to build the maze structure. \n",
    "- In here, we also define the positions of the starting area, the end goal, and the sub goal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the maze\n",
    "class Maze:\n",
    "    def __init__(self, maze, start_position, goal_position, sub_goal_position):\n",
    "        self.maze = maze\n",
    "        \n",
    "        self.maze_width = maze_struc.shape[1]           # rows of maze, also knows as x-azis. \n",
    "        self.maze_height = maze_struc.shape[0]          # columns of maze, also known as y-axis.\n",
    "\n",
    "        self.start_position = start_position            # start position - S.\n",
    "        self.goal_position = goal_position              # end goal position - E.\n",
    "        self.sub_goal_position = sub_goal_position      # sub goal position - G.\n",
    "\n",
    "    def show_maze(self):\n",
    "        plt.figure(figsize=(5,5))\n",
    "\n",
    "        plt.imshow(self.maze, cmap='Pastel1')\n",
    "\n",
    "        # Placements for the start, end, and sub goal positions.\n",
    "        plt.text(self.start_position[0], self.start_position[1], 'S', ha='center', va='center', color='green', fontsize=15)\n",
    "        plt.text(self.goal_position[0], self.goal_position[1], 'E', ha='center', va='center', color='red', fontsize=15)\n",
    "        plt.text(self.sub_goal_position[0], self.sub_goal_position[1], 'G', ha='center', va='center', color='blue', fontsize=15)\n",
    "\n",
    "        # Add grid lines between every wall/space.\n",
    "        plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "        plt.xticks(np.arange(0.5, self.maze.shape[1], 1))\n",
    "        plt.yticks(np.arange(0.5, self.maze.shape[0], 1))\n",
    "        plt.gca().set_xticks(np.arange(-0.5, self.maze.shape[1], 1), minor=True)\n",
    "        plt.gca().set_yticks(np.arange(-0.5, self.maze.shape[0], 1), minor=True)\n",
    "        plt.gca().grid(which='minor', color='grey', linestyle='-', linewidth=0.5)\n",
    "        plt.gca().tick_params(which='both', length=0)\n",
    "\n",
    "        plt.xlim(-0.45, self.maze.shape[1] - 0.5)\n",
    "        plt.ylim(self.maze.shape[0] - 0.6, -0.4)\n",
    "\n",
    "        # Hide the digits and labels from the plot visualistion. \n",
    "        plt.xticks([]), plt.yticks([])\n",
    "\n",
    "        # Ensures the plot will visualise when running the code.\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# The layout of the 10x10 maze:\n",
    "# 1 = wall.\n",
    "# 0 = open area.\n",
    "# (If wanted, we can later make another file where we can generate larger mazes like 100x100).\n",
    "maze_struc = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 1, 0, 1, 0, 1, 0, 1, 1],\n",
    "    [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "    [1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
    "    [1, 0, 1, 0, 0, 0, 0, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
    "    [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "])\n",
    "\n",
    "# Places the start, end, and sub goal at the correct coordinates (rows, columns).\n",
    "maze = Maze(maze_struc, (1, 1), (7, 8), (3,5))\n",
    "\n",
    "# Actually visualises the plot with matplotlib.\n",
    "maze.show_maze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Agent\n",
    "\n",
    "This is where the logic of the agent come in:\n",
    "- The agent can move in four directions. These are up, down, left, and right. \n",
    "- The q learning formula and logic will be applied to it. The parameters the agent will go off are:\n",
    "    - the learning rate → decides how much new information overrides over information.\n",
    "    - the discount factor → decides if the agent will prefer better rewards later on, or smaller awards right away\n",
    "    - exploration rate → exploration vs. exploitation. This code works with a decay, over time it will proper exploitation over exploration in the maze.\n",
    "\n",
    "- The agent is based on this formula of Q-Learning:\n",
    "\n",
    "$$ Q(s, a) ← Q(s, a) + α [r + γ max(a') Q(s', a') - Q(s, a)] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions the agent can take.\n",
    "moves = [\n",
    "   (-1, 0),         # Moving one step up.\n",
    "   (1, 0),          # Moving one step down.\n",
    "   (0, -1),         # Moving one step left.\n",
    "   (0, 1)           # Moving one step right.\n",
    "]\n",
    "\n",
    "# Initialise the Q-Learning agent \n",
    "class QLearningAgent:\n",
    "    def __init__(self, maze, learning_rate=0.1, discount_factor=0.9, exploration_start=1.0, exploration_end=0.01, num_episodes=100):\n",
    "        \n",
    "        # The table gets updated as new information is stored. 4 stands for the actions the agent can take. \n",
    "        self.q_table = np.zeros((maze.maze_height, maze.maze_width, 4)) \n",
    "         \n",
    "        self.learning_rate = learning_rate          \n",
    "        self.discount_factor = discount_factor      \n",
    "        self.exploration_start = exploration_start  \n",
    "        self.exploration_end = exploration_end\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "    # Calculates the rate of exploration to exploitation over time -> start with a lot of exploration and eventually prefer exploitation.\n",
    "    def get_exploration_rate(self, current_episode):\n",
    "        exploration_rate = self.exploration_start * (self.exploration_end / self.exploration_start) ** (current_episode / self.num_episodes)\n",
    "        return exploration_rate\n",
    "    \n",
    "    # Chooses what movement action to make. \n",
    "    def get_action(self, state, current_episode):\n",
    "        exploration_rate = self.get_exploration_rate(current_episode)\n",
    "\n",
    "        # Select an action for the given state either randomly (exploration) or using the Q-table (exploitation).\n",
    "        if np.random.rand() < exploration_rate:\n",
    "            return np.random.randint(4) \n",
    "        else:\n",
    "            #Chooses the action with the highest Q-value for the given state.\n",
    "            return np.argmax(self.q_table[state]) \n",
    "        \n",
    "    # Updates the Q-values in the Q-table based on its actions and states.\n",
    "    def update_q_table(self, state, action, next_state, reward):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "\n",
    "        current_q_value = self.q_table[state][action]\n",
    "\n",
    "        # Formula to update the Q-value based on the theory of the Q-Learning algorithm.\n",
    "        new_q_value = current_q_value + self.learning_rate * (reward + self.discount_factor * self.q_table[next_state][best_next_action] - current_q_value)\n",
    "\n",
    "        # Apply new Q-value for current action and state. \n",
    "        self.q_table[state][action] = new_q_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Agent in Maze\n",
    "\n",
    "This cell will show the behaviour of the agent in a single episode and before it is trained with the Q-Learning algorithm.\n",
    "\n",
    "- It DOES define the logic on the agent inside of the maze. In other words, giving the agent rewards and penalities for hitting walls and reaching the goal, respectively.\n",
    "- So, it keeps track of the total reward.\n",
    "- It also tracks the total steps the agent took.\n",
    "- It also updates the Q-values as necessary.\n",
    "\n",
    "Below, we first initialise the rewards or penalties the agent will receive based on its behaviour. Change as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewards.\n",
    "goal_reward = 100\n",
    "sub_goal_reward = 50\n",
    "\n",
    "# Penalities.\n",
    "wall_penalty = -10\n",
    "step_penalty = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qlearning_logic(agent, maze, current_episode, train=True):\n",
    "\n",
    "    current_state = maze.start_position     # Agent starts at start position.\n",
    "    path = [current_state]                  # Tracks the agent's current position.\n",
    "\n",
    "    goal_reached = False                    # Tracks if the agent reached the goal.\n",
    "    sub_reached = False                     # Tracks if the agent reached the sub goal.\n",
    "\n",
    "    episode_reward = 0                      # Tracks the agent's total reward at the end of the episode.\n",
    "    episode_step = 0                        # Tracks the agent's total steps at the end of the episode.\n",
    "    \n",
    "    while not goal_reached:\n",
    "\n",
    "        # Decide the agent's next action based on the Q-Table.\n",
    "        action = agent.get_action(current_state, current_episode)\n",
    "        next_state = (current_state[0] + moves[action][0], current_state[1] + moves[action][1])\n",
    "\n",
    "        # Give a penalty if a wall is hit.\n",
    "        if (next_state[0] < 0 or next_state[0] >= maze.maze_height or \n",
    "            next_state[1] < 0 or next_state[1] >= maze.maze_width or \n",
    "            maze.maze[next_state[1]][next_state[0]] == 1):\n",
    "            reward = wall_penalty\n",
    "            next_state = current_state\n",
    "\n",
    "        # Give a single-time reward if the sub-goal is reached.\n",
    "        elif next_state == maze.sub_goal_position and not sub_reached:\n",
    "            path.append(current_state)\n",
    "            reward = sub_goal_reward\n",
    "            sub_reached = True\n",
    "\n",
    "        # Mark that the agent has reached the end and give a reward.\n",
    "        elif next_state == maze.goal_position:\n",
    "            path.append(current_state)\n",
    "            reward = goal_reward\n",
    "            goal_reached = True\n",
    "\n",
    "        # Give a penalty every time the agent takes a step without reaching the final goal position.\n",
    "        else:\n",
    "            path.append(current_state)\n",
    "            reward = step_penalty\n",
    "\n",
    "        # Track the total steps and reward.\n",
    "        episode_reward += reward\n",
    "        episode_step += 1\n",
    "\n",
    "        # Update Q-table if training is set to True.\n",
    "        if train:\n",
    "            agent.update_q_table(current_state, action, next_state, reward)\n",
    "\n",
    "        # Update the agent's current position.\n",
    "        current_state = next_state\n",
    "\n",
    "    # Return total reward, steps, path, and whether the sub-goal was reached.\n",
    "    return episode_reward, episode_step, path, sub_reached\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Agent Test\n",
    "\n",
    "- This version shows how the agent behaves in a single episode without any training whatsoever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to visualise the maze.\n",
    "def visualize_maze(maze, path, sub_goal_reached):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(maze.maze, cmap='Pastel1')\n",
    "    \n",
    "    plt.text(maze.start_position[0], maze.start_position[1], 'S', ha='center', va='center', color='green', fontsize=15)\n",
    "    plt.text(maze.goal_position[0], maze.goal_position[1], 'E', ha='center', va='center', color='red', fontsize=15)\n",
    "    plt.text(maze.sub_goal_position[0], maze.sub_goal_position[1], 'G', ha='center', va='center', color='blue', fontsize=15)\n",
    "\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "    plt.xticks(np.arange(0.5, maze.maze.shape[1], 1))\n",
    "    plt.yticks(np.arange(0.5, maze.maze.shape[0], 1))\n",
    "    plt.gca().set_xticks(np.arange(-0.5, maze.maze.shape[1], 1), minor=True)\n",
    "    plt.gca().set_yticks(np.arange(-0.5, maze.maze.shape[0], 1), minor=True)\n",
    "    plt.gca().grid(which='minor', color='grey', linestyle='-', linewidth=0.5)\n",
    "    plt.gca().tick_params(which='both', length=0)\n",
    "\n",
    "    plt.xlim(-0.45, maze.maze.shape[1] - 0.5)\n",
    "    plt.ylim(maze.maze.shape[0] - 0.6, -0.4)\n",
    "\n",
    "    # Additionally show the path the agent took.\n",
    "    for position in path:\n",
    "        plt.text(position[0], position[1], \"●\", va='center', color='white', fontsize=8)\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows a single episode of the agent (untrained).\n",
    "def test_agent(agent, maze, num_episodes=1):\n",
    "    episode_reward, episode_step, path, sub_reached = qlearning_logic(agent, maze, num_episodes, train=False)\n",
    "\n",
    "    # Shows the path it took, total steps and total reward.\n",
    "    print(\"Final Path:\")\n",
    "    for row, col in path:\n",
    "        print(f\"({row}, {col})-> \", end='')\n",
    "    print(\"End Reached.\")\n",
    "\n",
    "    print(\"Total steps:\", episode_step)\n",
    "    print(\"Total reward:\", episode_reward)\n",
    "\n",
    "    # Visualize the maze with the agent's path.\n",
    "    visualize_maze(maze, path, sub_reached)\n",
    "\n",
    "    return episode_step, episode_reward\n",
    "\n",
    "agent = QLearningAgent(maze)\n",
    "test_agent(agent, maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat Map\n",
    "\n",
    "- Heat Map of untrained Agent through 5 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the agent and generate a heat map of the visited tiles\n",
    "def test_agent_with_heatmap(agent, maze, num_episodes=1):\n",
    "    visit_count = np.zeros((maze.maze_height, maze.maze_width))\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        _, _, path, _ = qlearning_logic(agent, maze, episode, train=False)\n",
    "        for position in path:\n",
    "            visit_count[position[1], position[0]] += 1  # Increment visit count for each position\n",
    "\n",
    "    # Plot the heat map\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(visit_count, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar(label='Visit Count')\n",
    "    plt.title('Heat Map of Tiles Visited by Agent')\n",
    "    plt.show()\n",
    "\n",
    "# Test the agent and generate the heat map\n",
    "test_agent_with_heatmap(agent, maze, num_episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Agent in the Maze\n",
    "\n",
    "- We are now going to train the agent. By saving it's previous attempts and learning from the information it learned, it should improve its behaviour over time over the course of its assigned number of episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def train_agent(agent, maze, num_episodes=100):\n",
    "    \n",
    "    # Store the data for the rewards and the steps (for plotting purposes).\n",
    "    episode_rewards = []\n",
    "    episode_steps = []\n",
    "    success_count = 0  # To count the number of successful episodes\n",
    "\n",
    "    # Create a visit count matrix to store how many times the agent visited each tile.\n",
    "    visit_count = np.zeros((maze.maze_height, maze.maze_width))\n",
    "\n",
    "    # Loop over the number of episodes.\n",
    "    for episode in range(num_episodes):\n",
    "        episode_reward, episode_step, path, sub_reached = qlearning_logic(agent, maze, episode, train=True)\n",
    "        \n",
    "        # Check if the agent reached the goal\n",
    "        if path[-1] == maze.goal_position:\n",
    "            success_count += 1\n",
    "\n",
    "        # Loop over the path the agent took and increment the visit count for each tile.\n",
    "        for position in path:\n",
    "            visit_count[position[1], position[0]] += 1  # Increment visit count for each position\n",
    "\n",
    "        # Add the rewards and steps to their respective lists.\n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_steps.append(episode_step)\n",
    "\n",
    "    # Calculate the moving average of rewards and steps to smooth out the data\n",
    "    window_size = 10\n",
    "    moving_avg_rewards = np.convolve(episode_rewards, np.ones(window_size)/window_size, mode='valid')\n",
    "    moving_avg_steps = np.convolve(episode_steps, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "    # Calculate success rate\n",
    "    success_rate = (success_count / num_episodes) * 100\n",
    "\n",
    "    # Calculate variance in rewards and steps\n",
    "    reward_variance = np.var(episode_rewards)\n",
    "    steps_variance = np.var(episode_steps)\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('Reward per Episode', 'Steps per Episode'))\n",
    "\n",
    "    # Add reward plot\n",
    "    fig.add_trace(go.Scatter(x=list(range(num_episodes)), y=episode_rewards, mode='lines', name='Rewards'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=list(range(window_size-1, num_episodes)), y=moving_avg_rewards, mode='lines', name='Moving Avg Rewards'), row=1, col=1)\n",
    "    fig.update_xaxes(title_text='Episode', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Cumulative Reward', row=1, col=1)\n",
    "\n",
    "    # Add steps plot\n",
    "    fig.add_trace(go.Scatter(x=list(range(num_episodes)), y=episode_steps, mode='lines', name='Steps'), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=list(range(window_size-1, num_episodes)), y=moving_avg_steps, mode='lines', name='Moving Avg Steps'), row=1, col=2)\n",
    "    fig.update_xaxes(title_text='Episode', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='Steps Taken', row=1, col=2)\n",
    "\n",
    "    # Plot the heat map\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(visit_count, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar(label='Visit Count')\n",
    "    plt.title('Heat Map of Tiles Visited by Agent')\n",
    "    plt.show()\n",
    "\n",
    "    # Print the final reward and steps after training finished.\n",
    "    final_reward = episode_rewards[-1]\n",
    "    final_steps = episode_steps[-1]\n",
    "\n",
    "    print(f\"The final reward after training is: {final_reward}\")\n",
    "    print(f\"The final steps after training are: {final_steps}\")\n",
    "    print(f\"Success rate: {success_rate}%\")\n",
    "    print(f\"Reward variance: {reward_variance}\")\n",
    "    print(f\"Steps variance: {steps_variance}\")\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final reward after training is: 137\n",
      "The final steps after training are: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Rewards",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x",
         "y": [
          -11161,
          -4943,
          -205,
          -223,
          -315,
          -207,
          -290,
          -173,
          -91,
          -149,
          -165,
          -67,
          111,
          71,
          -169,
          113,
          115,
          81,
          87,
          93,
          107,
          81,
          9,
          -55,
          119,
          87,
          79,
          105,
          135,
          107,
          117,
          117,
          137,
          135,
          121,
          127,
          125,
          135,
          137,
          127,
          117,
          115,
          125,
          135,
          113,
          137,
          127,
          125,
          137,
          125,
          -23,
          121,
          103,
          137,
          123,
          137,
          135,
          137,
          125,
          127,
          137,
          135,
          117,
          137,
          127,
          135,
          137,
          127,
          117,
          117,
          137,
          127,
          135,
          137,
          137,
          137,
          137,
          117,
          137,
          135,
          137,
          137,
          137,
          137,
          137,
          137,
          137,
          137,
          135,
          137,
          137,
          137,
          137,
          137,
          127,
          137,
          137,
          127,
          137,
          137
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines",
         "name": "Moving Avg Rewards",
         "type": "scatter",
         "x": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x",
         "y": [
          -1775.7,
          -676.0999999999999,
          -188.5,
          -156.9,
          -127.5,
          -112.9,
          -80.90000000000002,
          -40.400000000000006,
          -15.000000000000009,
          2.8000000000000043,
          27.000000000000004,
          54.2,
          69,
          58.80000000000001,
          46.2,
          75.00000000000001,
          72.4,
          68.80000000000001,
          71.2,
          76,
          77.4,
          78.4,
          82,
          94.80000000000001,
          113.80000000000001,
          114,
          118.00000000000001,
          122.60000000000001,
          125.60000000000001,
          125.80000000000001,
          127.80000000000001,
          127.80000000000003,
          127.60000000000001,
          126.40000000000002,
          126.4,
          125.60000000000001,
          126.60000000000001,
          126.80000000000001,
          125.8,
          125.80000000000001,
          125.60000000000001,
          111.60000000000001,
          112.20000000000002,
          110.00000000000001,
          110.20000000000002,
          111.2,
          111.20000000000002,
          112.00000000000001,
          113.2,
          112.00000000000001,
          112.20000000000002,
          128.20000000000002,
          129.60000000000002,
          131,
          131,
          131.4,
          131.20000000000002,
          131.4,
          130.4,
          129.60000000000002,
          128.60000000000002,
          128.60000000000002,
          127.80000000000001,
          129.60000000000002,
          129.60000000000002,
          130.60000000000002,
          130.8,
          130.8,
          129.8,
          131.8,
          133.60000000000002,
          133.60000000000002,
          134.60000000000002,
          134.8,
          134.8,
          134.8,
          134.8,
          134.8,
          136.8,
          136.60000000000002,
          136.8,
          136.8,
          136.8,
          136.8,
          136.8,
          135.8,
          135.8,
          135.8,
          134.8,
          135,
          135
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines",
         "name": "Steps",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x2",
         "y": [
          1998,
          991,
          69,
          105,
          107,
          80,
          85,
          82,
          72,
          85,
          83,
          75,
          23,
          27,
          105,
          21,
          19,
          26,
          20,
          32,
          18,
          26,
          53,
          81,
          24,
          20,
          28,
          20,
          17,
          27,
          17,
          17,
          15,
          17,
          22,
          16,
          18,
          17,
          15,
          16,
          17,
          19,
          18,
          17,
          21,
          15,
          16,
          18,
          15,
          18,
          148,
          22,
          31,
          15,
          20,
          15,
          17,
          15,
          18,
          16,
          15,
          17,
          17,
          15,
          16,
          17,
          15,
          16,
          17,
          17,
          15,
          16,
          17,
          15,
          15,
          15,
          15,
          17,
          15,
          17,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          17,
          15,
          15,
          15,
          15,
          15,
          16,
          15,
          15,
          16,
          15,
          15
         ],
         "yaxis": "y2"
        },
        {
         "mode": "lines",
         "name": "Moving Avg Steps",
         "type": "scatter",
         "x": [
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "xaxis": "x2",
         "y": [
          367.4,
          175.9,
          84.3,
          79.7,
          71.9,
          71.7,
          65.8,
          59.2,
          53.6,
          48.4,
          43.1,
          36.6,
          31.700000000000003,
          34.7,
          40.1,
          32,
          31.9,
          32.8,
          32.2,
          31.9,
          31.400000000000002,
          31.299999999999997,
          30.4,
          26.599999999999998,
          20.2,
          19.999999999999996,
          19.6,
          18.6,
          18.299999999999997,
          18.1,
          17.000000000000004,
          17.000000000000004,
          17.2,
          17.5,
          17.500000000000004,
          17.400000000000006,
          17.300000000000004,
          17.1,
          17.200000000000003,
          17.2,
          17.400000000000002,
          30.5,
          30.8,
          32.1,
          31.900000000000002,
          31.8,
          31.8,
          31.9,
          31.6,
          31.900000000000002,
          31.700000000000003,
          18.400000000000002,
          17.900000000000002,
          16.5,
          16.5,
          16.1,
          16.3,
          16.1,
          16.200000000000003,
          16.1,
          16.2,
          16.2,
          16.1,
          16.1,
          16.1,
          16,
          15.8,
          15.8,
          15.899999999999999,
          15.7,
          15.7,
          15.7,
          15.600000000000001,
          15.399999999999999,
          15.4,
          15.4,
          15.4,
          15.4,
          15.2,
          15.399999999999999,
          15.2,
          15.2,
          15.2,
          15.2,
          15.2,
          15.299999999999999,
          15.299999999999999,
          15.299999999999999,
          15.399999999999999,
          15.2,
          15.2
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Reward per Episode",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Steps per Episode",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Episode"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Episode"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Cumulative Reward"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Steps Taken"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training the agent\n",
    "train_agent(agent, maze, num_episodes=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Trained Agent\n",
    "\n",
    "- As you will probably see, if everything went well, the agent should now traverse through the maze the right way (fewest steps and highest rewards) after running the code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the agent after training\n",
    "test_agent(agent, maze, num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent and generate the heat map again\n",
    "test_agent_with_heatmap(agent, maze, num_episodes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animated showcase\n",
    "\n",
    "- Finally, a last animated version to see it go through the maze after it learned the best possible route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animated_test_agent(agent, maze, num_episodes=100):\n",
    "    last_episode_reward = 0\n",
    "    last_episode_steps = 0\n",
    "    last_episode_path = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        episode_reward, episode_step, path, sub_reached = qlearning_logic(agent, maze, episode, train=False)\n",
    "        \n",
    "        # Capture the last episode's results\n",
    "        if episode == num_episodes - 1:\n",
    "            last_episode_reward = episode_reward\n",
    "            last_episode_steps = episode_step\n",
    "            last_episode_path = path\n",
    "\n",
    "    print(f\"Final reward from last episode: {last_episode_reward}\")\n",
    "    print(f\"Final steps from last episode: {last_episode_steps}\")\n",
    "\n",
    "    return last_episode_reward, last_episode_steps, last_episode_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the agent after training and capturing the last episode's details\n",
    "last_reward, last_steps, last_path = animated_test_agent(agent, maze, num_episodes=100)\n",
    "\n",
    "# Animate only the last episode using the captured path\n",
    "def animate_last_episode(agent, maze, path):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    # Plot the initial maze positions.\n",
    "    ax.imshow(maze.maze, cmap='Pastel1')\n",
    "    ax.text(maze.start_position[0], maze.start_position[1], 'S', ha='center', va='center', color='green', fontsize=15)\n",
    "    ax.text(maze.goal_position[0], maze.goal_position[1], 'E', ha='center', va='center', color='red', fontsize=15)\n",
    "    sub_goal_marker = ax.text(maze.sub_goal_position[0], maze.sub_goal_position[1], 'G', ha='center', va='center', color='blue', fontsize=15)\n",
    "\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "    plt.xticks(np.arange(0.5, maze.maze.shape[1], 1))\n",
    "    plt.yticks(np.arange(0.5, maze.maze.shape[0], 1))\n",
    "    plt.gca().set_xticks(np.arange(-0.5, maze.maze.shape[1], 1), minor=True)\n",
    "    plt.gca().set_yticks(np.arange(-0.5, maze.maze.shape[0], 1), minor=True)\n",
    "    plt.gca().grid(which='minor', color='grey', linestyle='-', linewidth=0.5)\n",
    "    plt.gca().tick_params(which='both', length=0)\n",
    "\n",
    "    plt.xlim(-0.45, maze.maze.shape[1] - 0.5)\n",
    "    plt.ylim(maze.maze.shape[0] - 0.6, -0.4)\n",
    "\n",
    "    # Initialize the agent's position and direction marker.\n",
    "    agent_marker, = ax.plot(maze.start_position[0], maze.start_position[1], \"o\", color='white', markersize=10)\n",
    "    path_markers = []\n",
    "\n",
    "    def update(frame):\n",
    "        if frame < len(path):\n",
    "            pos = path[frame]\n",
    "\n",
    "            # Update agent marker position\n",
    "            agent_marker.set_data(pos[0], pos[1])\n",
    "\n",
    "            # Change the \"G\" sub-goal marker from blue to black when reached.\n",
    "            if pos == maze.sub_goal_position:\n",
    "                sub_goal_marker.set_color('black')\n",
    "\n",
    "        # If it's the last frame (goal reached), plot the entire path.\n",
    "        if frame == len(path) - 1:\n",
    "            for (x, y) in path:\n",
    "                marker, = ax.plot(x, y, \".\", color='white', markersize=10)\n",
    "                path_markers.append(marker)\n",
    "\n",
    "        return agent_marker, sub_goal_marker, *path_markers\n",
    "\n",
    "    # Animate the last episode path\n",
    "    anim = FuncAnimation(fig, update, frames=len(path), interval=100, blit=True, repeat=False)\n",
    "\n",
    "    print(\"Last Episode Path:\")\n",
    "    for row, col in path:\n",
    "        print(f\"({row}, {col})-> \", end='')\n",
    "    print(\"End Reached\")\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.grid(color='black', linewidth=2)\n",
    "\n",
    "    return anim\n",
    "\n",
    "# Animate the last episode\n",
    "anim_last_episode = animate_last_episode(agent, maze, last_path)\n",
    "\n",
    "# Convert the animation to HTML for inline display in the notebook.\n",
    "HTML(anim_last_episode.to_jshtml())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntroRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
